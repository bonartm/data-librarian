<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Modul 3 on data librarian - modul 3 - daten analysieren und verstehen</title>
    <link>https://bonartm.github.io/data-librarian/</link>
    <description>Recent content in Modul 3 on data librarian - modul 3 - daten analysieren und verstehen</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>de-DE</language>
    
	<atom:link href="https://bonartm.github.io/data-librarian/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Lösungen zu den Kursaufgaben</title>
      <link>https://bonartm.github.io/data-librarian/solutions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/solutions/</guid>
      <description>Im Laufe des Kurses werden hier die Lösungen zu den einzelnen Aufgaben hochgeladen. Die Projektaufgaben werden am Präsenztag gesammelt besprochen.
Kursorganisation und Vorbereitung Quiz  Strg+Enter siehe hier: https://docs.anaconda.com/anaconda/packages/pkg-docs/ 423448, len(df) siehe (unter sns.set()): https://seaborn.pydata.org/introduction.html  Jan gilt.), diskret, `object` - `temp`: metrisch, stetig, `int` - `below_zero`: nominal, diskret, `boolean` #### Datenrundreise   Lösungen   solutions_datenrundreise.ipynb  (35 ko)    #### Exkurs: Einlesen von Daten - In Linux kann z.</description>
    </item>
    
    <item>
      <title>numpy</title>
      <link>https://bonartm.github.io/data-librarian/organisation/packages/numpy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/packages/numpy/</guid>
      <description>numpy bietet den array als zentrale Datenstruktur. Mit ihm lassen sich numerische Daten effizient im Arbeitsspeicher (RAM) erstellen, ein- und auslesen, bearbeiten und aggregieren.
Numpy bietet neben dem array viele Funktionen an, mit denen sich effizient Berechnungen auf diesen durchführen lassen können. Außerdem wird die klassische Matrizenrechnung unterstützt.
# import the library and give it a shorter name &amp;#39;np&amp;#39; import numpy as np # create 100 randomly distributed numbers X = np.</description>
    </item>
    
    <item>
      <title>Kurseinheiten</title>
      <link>https://bonartm.github.io/data-librarian/organisation/modules/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/modules/</guid>
      <description>Wir haben das Modul in wöchentliche Einheiten, die jeweils ein Gebiet aufgreifen und vertiefen, unterteilt. Sie können sich die Zeit für die Bearbeitung der Einheiten selber aufteilen, sollten aber jede Einheit am Ende der jeweiligen Woche abgeschlossen haben. Am Ende einer Woche wird die nächste Einheit auf dieser Webeite freigeschaltet.
Jede Einheit umfasst kleine praktische Projekt, welche Sie in Form eines Jupyter Notebooks bearbeiten und aufbereiten.
Der erste Teil des Moduls (21-01 - 15.</description>
    </item>
    
    <item>
      <title>Termine</title>
      <link>https://bonartm.github.io/data-librarian/organisation/schedule/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/schedule/</guid>
      <description>Hier finden Sie einen Überblick über die einzelnen Moduleinheiten.
   Datum Titel Ziele     21.01 – 26.01 Vorbereitung Installieren Sie die benötigte Software Laden Sie die Kursmaterialien und Datensätze herunter Stellen Sie sicher, dass Python Notebooks lokal ausgeführt werden können   27.01 – 02.02 Grundlagen Beschreiben Sie Datensätze mit dem statistischen Grundvokabular Lesen Sie Datensätze als DataFrames in Python ein Filtern Sie DataFrames nach Spalten oder Zeilen Erstellen Sie neue Variablen   03.</description>
    </item>
    
    <item>
      <title>Conda und Anaconda</title>
      <link>https://bonartm.github.io/data-librarian/organisation/anaconda/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/anaconda/</guid>
      <description>Conda ist eine freie und offene Softwarepaketverwaltung für Python. Neben der Möglichkeit, Pakete (packages, libraries) für Python aus dem Internet zu installieren, können mit conda virtuelle Umgebungen (environments) angelegt werden. Diese Umgebungen beinhalten nur die Pakete und Python Versionen, die für ein spezifisches Projekt gebraucht werden. Umgebungen können mit anderen Personen geteilt werden, sodass sichergestellt ist, dass alle Programmierer mit den gleichen Paketen und Versionen arbeiten, auch wenn sie unterschiedliche Systeme (Windows, Linux, MacOS) verwenden.</description>
    </item>
    
    <item>
      <title>Jupyter Notebooks</title>
      <link>https://bonartm.github.io/data-librarian/organisation/notebooks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/notebooks/</guid>
      <description>Die Projekt-Aufgaben und Code-Beispiele in diesem Modul werden über Jupyter Notebooks erstellt und verteilt.
Jupyter Notebooks bieten eine browserbasierte graphische Schnittstelle zur Python Programmierumgebung. Deswegen können Notebooks auf jedem System gestartet werden, man benötigt dazu nur einen Web-Browser und eine lokale installierte Version von Python.
Darüber hinaus bieten Notebooks die Möglichkeit Text, Visualisierungen und Code in einer integrierten Datei zu erstellen. Somit können einfach statistische Reports und Analysen erstellt werden. Die Replizierbarkeit der Ergebnisse ist auch gewährleistet, da jede Person, die Programmierschritte im Notebook auf dem eignen Rechner wiederholen kann.</description>
    </item>
    
    <item>
      <title>San Francisco Library Usage</title>
      <link>https://bonartm.github.io/data-librarian/organisation/dataset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/dataset/</guid>
      <description>Im ersten Teil des Moduls werden Sie einen offenen Kundendatensatz der Bibliothek in San Francisco analysieren.
 The Integrated Library System (ILS) is composed of bibliographic records including inventoried items, and patron records including circulation data. The data is used in the daily operation of the library, including circulation, online public catalog, cataloging, acquisitions, collection development, processing, and serials control. This dataset represents the usage of inventoried items by patrons &amp;hellip; (Abstract taken from here)</description>
    </item>
    
    <item>
      <title>Recap: Quiz</title>
      <link>https://bonartm.github.io/data-librarian/organisation/quiz_intro/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/quiz_intro/</guid>
      <description>.quiz fieldset { border-color: black; border-width: 10px; margin-bottom: 1em; } .quiz legend { font-size: 105%; font-weight: 600; padding-left: 15px; padding-right: 15px; padding-top: 15px; } .quiz label { display: block; line-height: 1.75em; } .quiz input[type=&#34;radio&#34;] { margin-right: 10px; page-break-after: avoid; page-break-before: avoid; } .quiz input[type=&#34;submit&#34;] { background: black; color: white; display: block; font-size: 120%; font-weight: 600; height: 2.5em; margin-top: 2em; text-transform: uppercase; width: 100%; } .quiz table { color: white; font-weight: bold; margin: 1em auto 2em auto; width: 100%; } .</description>
    </item>
    
    <item>
      <title>pandas</title>
      <link>https://bonartm.github.io/data-librarian/organisation/packages/pandas/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/packages/pandas/</guid>
      <description>pandas baut auf numpy auf und vereinfacht stark die Bearbeitung, Transformation, Aggregation und Zusammenfassung von zweidimensionalen Datensätzen sowie deren Import und Export in Python. Die zentralen Datenstrukturen in pandas sind Series und DataFrame.
Series sind eindimensionale Listen eines Datentypes, ähnlich wie arrays in numpy. Datentypen können ganzzahlige Zahlen (int), binäre Werte vom Typ true oder false (bool), Strings (str) oder reale Zahlen (float) sein.
In einem DataFrame werden mehrere Series gleicher Länge spaltenweise zu einer zweidimensionalen Tabelle (wie einer Excel Tabelle) zusammengefasst.</description>
    </item>
    
    <item>
      <title>matplotlib</title>
      <link>https://bonartm.github.io/data-librarian/organisation/packages/matplotlib/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/packages/matplotlib/</guid>
      <description>matplotlib ist das Standard-Paket zum Erstellen von wissenschaftlichen 2-dimensionalen statischen Graphiken. Die grundlegende Struktur in matplotlib ist figure, eine leere graphische Fläche, die mit Linien, Balken, Punten, Beschriftungen und Axen befüllt werden kann. Der fertige Plot kann dann in diversen Formaten abgespeichert oder auf dem Bildschirm angezeigt werden.
# import the package and give it the shorter name &amp;#39;plt&amp;#39; # matplotlib inline import matplotlib.pyplot as plt # create some dummy data x = range(1, 10) # make a simple scatter plot of the data plt.</description>
    </item>
    
    <item>
      <title>seaborn</title>
      <link>https://bonartm.github.io/data-librarian/organisation/packages/seaborn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/packages/seaborn/</guid>
      <description>seaborn baut auf matplotlib auf und bietet eine Vielzahl von Funktionen, die es erlauben schnell und einfach schöne statistische Visualisierungen zu erstellen. Seaborn ist also keine komplett eigenenständige Graphik-Bibliothek, sondern nutzt intern die Funktionalitäten und Datenstrukturen von matplotlib.
Eine wichtige Funktion ist die sns.set() Methode. Wenn sie am Anfang eines Python-Scripts ausgeführt wird, wird intern das Design der Plots erheblich verbessert. Alle plots, die nach dem Aufruf der Funktion erstellt werden, sehen viel besser aus.</description>
    </item>
    
    <item>
      <title>scipy</title>
      <link>https://bonartm.github.io/data-librarian/organisation/packages/scipy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/packages/scipy/</guid>
      <description>scipy ist fest mit numpy und pandas verbunden und bietet eine Menge an Funktionen und Methoden aus der Mathematik und Statistik an.
Für uns ist vor alle das Paket scipy.stats Interessant. Mit ihm können Zufallszahlen aus verschiedensten statistischen Verteilungen generiert werden oder auch statistische Tests durchgeführt werden. Hier finden Sie einen Überblick über alle Methoden des Pakets.
Im folgenden Beispiel wird ein Zweistichproben-t-Test an zwei numerischen Listen durchgeführt.
# import the package stats from the library scipy from scipy import stats # create two numerical arrays x = [12, 10, 11, 13, 14, 10, 13, 13, 22] y = [1, 4, 2, 3, 5, 2, 1, 0, 0, 1, 2] # perform a two sample t-test, to test if the samples have different means stats.</description>
    </item>
    
    <item>
      <title>scitkit-learn</title>
      <link>https://bonartm.github.io/data-librarian/organisation/packages/scikitlearn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/packages/scikitlearn/</guid>
      <description>scikit-learn ist eine umfangreiche Bibliothek für maschinelles Lernen in Python. Es bietet eine Vielzahl an verschiedenen Algorithmen, mit denen zum Beispiel Vorhersagen oder Bilderkennung durchgeführt werden können.
  Faces recognition example using eigenfaces and SVMshttps://scikit-learn.org/stable/auto_examples/applications/plot_face_recognition.html#sphx-glr-auto-examples-applications-plot-face-recognition-py
  # import the packages import numpy as np from sklearn.linear_model import LinearRegression # create some dummy dependent and independent variable X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]]) y = - 1 * X[:,0] + 2 * X[:,1] # estimate a linear regression and print out the coefficients reg = LinearRegression().</description>
    </item>
    
  </channel>
</rss>