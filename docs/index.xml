<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Modul 3 on data librarian - modul 3 - daten analysieren und verstehen</title>
    <link>https://bonartm.github.io/data-librarian/</link>
    <description>Recent content in Modul 3 on data librarian - modul 3 - daten analysieren und verstehen</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>de-DE</language>
    
	<atom:link href="https://bonartm.github.io/data-librarian/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Cheat Sheet</title>
      <link>https://bonartm.github.io/data-librarian/cheatsheet/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/cheatsheet/</guid>
      <description>Other Resources  https://librarycarpentry.org/ https://automatetheboringstuff.com/ https://librarycarpentry.org/lc-python-intro/  read in .csv files import pandas as pd file_path = &#39;./Library_Usage.csv&#39; df = pd.read_csv(file_path)  show column names and their types df.columns df.dtypes  number of rows len(df)  summarize functions df.head() df.tail() df.describe()  filter on columns df[[&amp;quot;colA&amp;quot;, &amp;quot;colB&amp;quot;, &amp;quot;colC&amp;quot;]]  filter on rows by index df.iloc[[1, 10, 15]]  filter on rows by logical query df.loc[df[&amp;quot;colA&amp;quot;] &amp;gt; 100]  some descriptive statistics for columns df[&amp;quot;colA&amp;quot;].</description>
    </item>
    
    <item>
      <title>Ein- und Ausgabe</title>
      <link>https://bonartm.github.io/data-librarian/basics/pandas/io/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/basics/pandas/io/</guid>
      <description> Übung 2: Einführung in Pandas  Laden Sie [dieses Jupyter Notebook]() in Ihren Projektordner. In dem Ordner sollte sich auch der Kunden-Datensatz mit dem Namen Library_Usage.csv befinden. Öffnen und bearbeiten Sie das Notebook mit Jupyter.  </description>
    </item>
    
    <item>
      <title>numpy</title>
      <link>https://bonartm.github.io/data-librarian/organisation/packages/numpy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/packages/numpy/</guid>
      <description>numpy bietet den array als zentrale Datenstruktur. Mit ihm lassen sich numerische Daten effizient im Arbeitsspeicher (RAM) erstellen, ein- und auslesen, bearbeiten und aggregieren.
Numpy bietet neben dem array viele Funktionen an, mit denen sich effizient Berechnungen auf diesen durchführen lassen können. Außerdem wird die klassische Matrizenrechnung unterstützt.
# import the library and give it a shorter name &#39;np&#39; import numpy as np # create 100 randomly distributed numbers X = np.</description>
    </item>
    
    <item>
      <title>Statistik</title>
      <link>https://bonartm.github.io/data-librarian/basics/ml/statistic/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/basics/ml/statistic/</guid>
      <description>Justus Perthes (1838): Rhein, Elbe und Oder   Statistik ist die traditionelle Wissenschaft von der Erhebung und Analyse von Daten. Sie verfügt über eine großes theoretisches und mathematisches Fundament und lässt sich in die Teilgebiete deskriptive (Beschreiben), explorative (Suchen) und schließende (Induktion) Statistik unterteilen.
Lesen Sie mehr über die Grundlagen der Statistik im Kapitel Grundbegriffe der Statistik.</description>
    </item>
    
    <item>
      <title>Machine Learning</title>
      <link>https://bonartm.github.io/data-librarian/basics/ml/ml/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/basics/ml/ml/</guid>
      <description>Seit der Erfindung des Personal Computers und des Internets werden statistische Probleme immer komplexer und größer und die neuen Datenmengen erfordern neue effiziente Strukturen zum Speichern und Auffinden der Informationen.
Maschinelles Lernen (&amp;ldquo;Statistical Learning&amp;rdquo;) bedeutet in diesem Kontext relevante und signifikante Muster und Trends aus den Daten zu extrahieren und die Daten &amp;ldquo;zu verstehen&amp;rdquo;. Dabei spielen Computer und deren wachsende Rechenpower eine immer größere Rolle. Sie haben die klassische Statistik revolutioniert und es sind vor allem Ingenieure und Informatiker, die die Weiterentwicklung der Disziplin heutzutage vorantreiben.</description>
    </item>
    
    <item>
      <title>Selektion von Spalten und Zeilen</title>
      <link>https://bonartm.github.io/data-librarian/basics/pandas/selection/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/basics/pandas/selection/</guid>
      <description> Übung 2: Einführung in Pandas  Laden Sie [dieses Jupyter Notebook]() in Ihren Projektordner. In dem Ordner sollte sich auch der Kunden-Datensatz mit dem Namen Library_Usage.csv befinden. Öffnen und bearbeiten Sie das Notebook mit Jupyter.  </description>
    </item>
    
    <item>
      <title>Data Science</title>
      <link>https://bonartm.github.io/data-librarian/basics/ml/data-science/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/basics/ml/data-science/</guid>
      <description>Grundsätzlich ist ein Data Scientist jemand, die oder der Wissen und Erkenntnisse aus strukturierten und unstrukturierten Daten gewinnt. Data Science ist eine interdisziplinäre Disziplin, denn sie liefert eine Sammlung an quantitativen Methoden- und Algorithmen, die in einem Fachgebiet angewandt werden können 1. Damit liegt Data Science irgendwo in der Schnittmenge von Mathe/ Statistik, Programmierung (&amp;ldquo;Hacking skills&amp;rdquo;) und Fachwissen (&amp;ldquo;domain knowledge&amp;rdquo;/ &amp;ldquo;substantive expertise&amp;rdquo;).
Aufgrund der stark angewachsenen Mengen an unstrukturierten Daten aus heterogenen Datenquellen (Text, Bilder, Sensoren, Netzwerke, Videos, &amp;hellip;) reichen die Methoden und Fertigkeiten, die die Statistik traditionellerweise liefert und vermittelt, nicht mehr aus, um diese Daten effizient zu strukturieren, aggregieren, kombinieren, analysieren und visualisieren zu können:</description>
    </item>
    
    <item>
      <title>Fehlende Werte</title>
      <link>https://bonartm.github.io/data-librarian/basics/pandas/na/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/basics/pandas/na/</guid>
      <description> Übung 2: Einführung in Pandas  Laden Sie [dieses Jupyter Notebook]() in Ihren Projektordner. In dem Ordner sollte sich auch der Kunden-Datensatz mit dem Namen Library_Usage.csv befinden. Öffnen und bearbeiten Sie das Notebook mit Jupyter.  </description>
    </item>
    
    <item>
      <title>Aggregation und Gruppierung</title>
      <link>https://bonartm.github.io/data-librarian/basics/pandas/groupby/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/basics/pandas/groupby/</guid>
      <description> Übung 2: Einführung in Pandas  Laden Sie [dieses Jupyter Notebook]() in Ihren Projektordner. In dem Ordner sollte sich auch der Kunden-Datensatz mit dem Namen Library_Usage.csv befinden. Öffnen und bearbeiten Sie das Notebook mit Jupyter.  </description>
    </item>
    
    <item>
      <title>Kurseinheiten</title>
      <link>https://bonartm.github.io/data-librarian/organisation/modules/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/modules/</guid>
      <description>Wir haben das Modul in wöchentliche Einheiten, die jeweils ein Gebiet aufgreifen und vertiefen, unterteilt. Sie können sich die Zeit für die Bearbeitung der Einheiten selber aufteilen, sollten aber jede Einheit am Ende der jeweiligen Woche abgeschlossen haben. Am Ende einer Woche wird die nächste Einheit auf dieser Webeite freigeschaltet.
Jede Einheit umfasst ein kleines praktisches Projekt, welches Sie in Form eines Jupyter Notebooks bearbeiten und aufbereiten. Ihr Notebook können Sie einreichen, um Feedback von den Kursleitern zu erhalten.</description>
    </item>
    
    <item>
      <title>Termine</title>
      <link>https://bonartm.github.io/data-librarian/organisation/schedule/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/schedule/</guid>
      <description>Hier finden Sie einen Überblick über die einzelnen Moduleinheiten. Die Tabelle können Sie sich auch als .pdf anzeigen lassen und ausdrucken:
  Überblick Modul 3   überblick_modul3.pdf  (25 ko)       Datum Titel Ziele     21.01 – 26.01 Vorbereitung Installieren Sie die benötigte Software Laden Sie die Kursmaterialien und Datensätze herunter Stellen Sie sicher, dass Python Notebooks lokal ausgeführt werden können   27.</description>
    </item>
    
    <item>
      <title>Conda und Anaconda</title>
      <link>https://bonartm.github.io/data-librarian/organisation/anaconda/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/anaconda/</guid>
      <description>Conda ist eine freie und offene Softwarepaketverwaltung für Python. Neben der Möglichkeit, Pakete (packages, libraries) für Python aus dem Internet zu installieren, können mit conda virtuelle Umgebungen (environments) angelegt werden. Diese Umgebungen beinhalten nur die Pakete und Python Versionen, die für ein spezifisches Projekt gebraucht werden. Umgebungen können mit anderen Personen geteilt werden, sodass sichergestellt ist, dass alle Programmierer mit den gleichen Paketen und Versionen arbeiten, auch wenn sie unterschiedliche Systeme (Windows, Linux, MacOS) verwenden.</description>
    </item>
    
    <item>
      <title>Jupyter Notebooks</title>
      <link>https://bonartm.github.io/data-librarian/organisation/notebooks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/notebooks/</guid>
      <description>Die Projekt-Aufgaben und Code-Beispiele in diesem Modul werden über Jupyter Notebooks erstellt und verteilt.
Jupyter Notebooks bieten eine browserbasierte graphische Schnittstelle zur Python Programmierumgebung. Deswegen können Notebooks auf jedem System gestartet werden, man benötigt dazu nur einen Web-Browser und eine lokale installierte Version von Python.
Darüber hinaus bieten Notebooks die Möglichkeit Text, Visualisierungen und Code in einer integrierten Datei zu erstellen. Somit können einfach statistische Reports und Analysen erstellt werden. Die Replizierbarkeit der Ergebnisse ist auch gewährleistet, da jede Person, die Programmierschritte im Notebook auf ihrem Rechner wiederholen kann.</description>
    </item>
    
    <item>
      <title>San Francisco Library Usage</title>
      <link>https://bonartm.github.io/data-librarian/organisation/dataset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/dataset/</guid>
      <description>Im ersten Teil des Moduls werden Sie einen offenen Kundendatensatz der Bibliothek in San Francisco analysieren.
 The Integrated Library System (ILS) is composed of bibliographic records including inventoried items, and patron records including circulation data. The data is used in the daily operation of the library, including circulation, online public catalog, cataloging, acquisitions, collection development, processing, and serials control. This dataset represents the usage of inventoried items by patrons &amp;hellip; (Abstract taken from here)</description>
    </item>
    
    <item>
      <title>Recap: Quiz</title>
      <link>https://bonartm.github.io/data-librarian/organisation/quiz_intro/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/quiz_intro/</guid>
      <description>.quiz fieldset { border-color: black; border-width: 10px; margin-bottom: 1em; } .quiz legend { font-size: 105%; font-weight: 600; padding-left: 15px; padding-right: 15px; padding-top: 15px; } .quiz label { display: block; line-height: 1.75em; } .quiz input[type=&#34;radio&#34;] { margin-right: 10px; page-break-after: avoid; page-break-before: avoid; } .quiz input[type=&#34;submit&#34;] { background: black; color: white; display: block; font-size: 120%; font-weight: 600; height: 2.5em; margin-top: 2em; text-transform: uppercase; width: 100%; } .quiz table { color: white; font-weight: bold; margin: 1em auto 2em auto; width: 100%; } .</description>
    </item>
    
    <item>
      <title>Grundbegriffe der Statistik</title>
      <link>https://bonartm.github.io/data-librarian/basics/basic_terms/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/basics/basic_terms/</guid>
      <description>In der Kursumgebung finden Sie das Einführungskapitel des Buchs Statistik: Der Weg zur Datenanalyse zum alleinigen persönlichen Gebrauch hier im Kurs hinterlegt.1
Der Text gibt einen Einstieg in die Aufgaben und Anwendungsbereiche der Statistik und erklärt die grundlegenden Begriffe, mit denen Daten und Datensätze charakterisiert werden können.
Beantworten und diskutieren Sie folgende Fragen konkret für den San Francisco Library Usage Datensatz. Halten Sie Ihre Ergebnisse in Stichpunkten in einem Jupyter Notebook fest.</description>
    </item>
    
    <item>
      <title>Streuungsmaße</title>
      <link>https://bonartm.github.io/data-librarian/descriptive_statistics/variance/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/descriptive_statistics/variance/</guid>
      <description>Seit einigen Jahren ist der Begriff Data Science sehr populär geworden. Die Nachfrage nach Data Scientists auf dem Arbeitsmarkt ist sehr hoch, Studiengänge werden neu eingerichtet oder umbenannt. Was unterscheidet einen Data Scientist eigentlich von einer Statistikerin?
Machinelles Lernen und insbesondere Themen wie künstliche Intelligenz, Neuronale Netze und Deep Learning sind immer wieder Thema in Zeitungen und Nachrichten. Was bedeuten diese Begriffe und wo ist da der Bezug zur Statistik?</description>
    </item>
    
    <item>
      <title>Beschreibung von univariaten Verteilungen</title>
      <link>https://bonartm.github.io/data-librarian/descriptive_statistics/density/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/descriptive_statistics/density/</guid>
      <description>Seit einigen Jahren ist der Begriff Data Science sehr populär geworden. Die Nachfrage nach Data Scientists auf dem Arbeitsmarkt ist sehr hoch, Studiengänge werden neu eingerichtet oder umbenannt. Was unterscheidet einen Data Scientist eigentlich von einer Statistikerin?
Machinelles Lernen und insbesondere Themen wie künstliche Intelligenz, Neuronale Netze und Deep Learning sind immer wieder Thema in Zeitungen und Nachrichten. Was bedeuten diese Begriffe und wo ist da der Bezug zur Statistik?</description>
    </item>
    
    <item>
      <title>Kreuztabellen</title>
      <link>https://bonartm.github.io/data-librarian/descriptive_statistics/bivariate/cross_tables/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/descriptive_statistics/bivariate/cross_tables/</guid>
      <description>Seit einigen Jahren ist der Begriff Data Science sehr populär geworden. Die Nachfrage nach Data Scientists auf dem Arbeitsmarkt ist sehr hoch, Studiengänge werden neu eingerichtet oder umbenannt. Was unterscheidet einen Data Scientist eigentlich von einer Statistikerin?
Machinelles Lernen und insbesondere Themen wie künstliche Intelligenz, Neuronale Netze und Deep Learning sind immer wieder Thema in Zeitungen und Nachrichten. Was bedeuten diese Begriffe und wo ist da der Bezug zur Statistik?</description>
    </item>
    
    <item>
      <title>Korrelation</title>
      <link>https://bonartm.github.io/data-librarian/descriptive_statistics/bivariate/correlation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/descriptive_statistics/bivariate/correlation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Quiz: Deskriptive Statistik</title>
      <link>https://bonartm.github.io/data-librarian/descriptive_statistics/quiz_statistics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/descriptive_statistics/quiz_statistics/</guid>
      <description>.quiz fieldset { border-color: black; border-width: 10px; margin-bottom: 1em; } .quiz legend { font-size: 105%; font-weight: 600; padding-left: 15px; padding-right: 15px; padding-top: 15px; } .quiz label { display: block; line-height: 1.75em; } .quiz input[type=&#34;radio&#34;] { margin-right: 10px; page-break-after: avoid; page-break-before: avoid; } .quiz input[type=&#34;submit&#34;] { background: black; color: white; display: block; font-size: 120%; font-weight: 600; height: 2.5em; margin-top: 2em; text-transform: uppercase; width: 100%; } .quiz table { color: white; font-weight: bold; margin: 1em auto 2em auto; width: 100%; } .</description>
    </item>
    
    <item>
      <title>Reflexion: Daten an Ihrem Arbeitsplatz</title>
      <link>https://bonartm.github.io/data-librarian/basics/reflection/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/basics/reflection/</guid>
      <description>Schreiben Sie einen kurzen Text über die Verwendung von Daten und quantitativen Methoden an Ihrem Arbeitsplatz. Denken Sie dabei über folgende Fragen nach:
 Welche Daten sind bei Ihnen vorhanden? Mit welchen Daten arbeiten Sie oder würden Sie gerne arbeiten? Werden statistische Verfahren oder Maschinelles Lernen schon bei Ihnen eingesetzt? Welche Fragen oder Phänomene würden Sie gerne untersuchen? Was fänden Sie spannend herauszufinden?  Teilen Sie Ihren Text mit den anderen KursteilnehmerInnen auf der Kursplattform.</description>
    </item>
    
    <item>
      <title>Tutorial</title>
      <link>https://bonartm.github.io/data-librarian/descriptive_statistics/visualizations/tutorial/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/descriptive_statistics/visualizations/tutorial/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Beispiele</title>
      <link>https://bonartm.github.io/data-librarian/descriptive_statistics/visualizations/examples/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/descriptive_statistics/visualizations/examples/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Quiz: Pandas-Bibliothek</title>
      <link>https://bonartm.github.io/data-librarian/basics/quiz_pandas/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/basics/quiz_pandas/</guid>
      <description>.quiz fieldset { border-color: black; border-width: 10px; margin-bottom: 1em; } .quiz legend { font-size: 105%; font-weight: 600; padding-left: 15px; padding-right: 15px; padding-top: 15px; } .quiz label { display: block; line-height: 1.75em; } .quiz input[type=&#34;radio&#34;] { margin-right: 10px; page-break-after: avoid; page-break-before: avoid; } .quiz input[type=&#34;submit&#34;] { background: black; color: white; display: block; font-size: 120%; font-weight: 600; height: 2.5em; margin-top: 2em; text-transform: uppercase; width: 100%; } .quiz table { color: white; font-weight: bold; margin: 1em auto 2em auto; width: 100%; } .</description>
    </item>
    
    <item>
      <title>Quiz: Visualisierungen</title>
      <link>https://bonartm.github.io/data-librarian/descriptive_statistics/quiz_visualizations/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/descriptive_statistics/quiz_visualizations/</guid>
      <description>.quiz fieldset { border-color: black; border-width: 10px; margin-bottom: 1em; } .quiz legend { font-size: 105%; font-weight: 600; padding-left: 15px; padding-right: 15px; padding-top: 15px; } .quiz label { display: block; line-height: 1.75em; } .quiz input[type=&#34;radio&#34;] { margin-right: 10px; page-break-after: avoid; page-break-before: avoid; } .quiz input[type=&#34;submit&#34;] { background: black; color: white; display: block; font-size: 120%; font-weight: 600; height: 2.5em; margin-top: 2em; text-transform: uppercase; width: 100%; } .quiz table { color: white; font-weight: bold; margin: 1em auto 2em auto; width: 100%; } .</description>
    </item>
    
    <item>
      <title>pandas</title>
      <link>https://bonartm.github.io/data-librarian/organisation/packages/pandas/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/packages/pandas/</guid>
      <description>pandas baut auf numpy auf und vereinfacht stark die Bearbeitung, Transformation, Aggregation und Zusammenfassung von zweidimensionalen Datensätzen sowie deren Import und Export in Python. Die zentralen Datenstrukturen in pandas sind Series und DataFrame.
Series sind eindimensionale Listen eines Datentypes, ähnlich wie arrays in numpy. Datentypen können ganzzahlige Zahlen (int), binäre Werte vom Typ true oder false (bool), Strings (str) oder reale Zahlen (float) sein.
In einem DataFrame werden mehrere Series gleicher Länge spaltenweise zu einer zweidimensionalen Tabelle (wie einer Excel Tabelle) zusammengefasst.</description>
    </item>
    
    <item>
      <title>Überblick</title>
      <link>https://bonartm.github.io/data-librarian/inference/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/inference/overview/</guid>
      <description></description>
    </item>
    
    <item>
      <title>matplotlib</title>
      <link>https://bonartm.github.io/data-librarian/organisation/packages/matplotlib/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/packages/matplotlib/</guid>
      <description>matplotlib ist das Standard-Paket zum Erstellen von wissenschaftlichen 2-dimensionalen statischen Graphiken. Die grundlegende Struktur in matplotlib ist figure, eine leere graphische Fläche, die mit Linien, Balken, Punten, Beschriftungen und Axen befüllt werden kann. Der fertige Plot kann dann in diversen Formaten abgespeichert oder auf dem Bildschirm angezeigt werden.
# import the package and give it the shorter name &#39;plt&#39; # matplotlib inline import matplotlib.pyplot as plt # create some dummy data x = range(1, 10) # make a simple scatter plot of the data plt.</description>
    </item>
    
    <item>
      <title>Mittelwertvergleiche</title>
      <link>https://bonartm.github.io/data-librarian/inference/ttest/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/inference/ttest/</guid>
      <description></description>
    </item>
    
    <item>
      <title>seaborn</title>
      <link>https://bonartm.github.io/data-librarian/organisation/packages/seaborn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/packages/seaborn/</guid>
      <description>seaborn baut auf matplotlib auf und bietet eine Vielzahl von Funktionen, die es erlauben schnell und einfach schöne statistische Visualisierungen zu erstellen. Seaborn ist also keine komplett eigenenständige Graphik-Bibliothek, sondern nutzt intern die Funktionalitäten und Datenstrukturen von matplotlib.
Eine wichtige Funktion ist die sns.set() Methode. Wenn sie am Anfang eines Python-Scripts ausgeführt wird, wird intern das Design der Plots erheblich verbessert. Alle plots, die nach dem Aufruf der Funktion erstellt werden, sehen viel besser aus.</description>
    </item>
    
    <item>
      <title>scipy</title>
      <link>https://bonartm.github.io/data-librarian/organisation/packages/scipy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/packages/scipy/</guid>
      <description>scipy ist fest mit numpy und pandas verbunden und bietet eine Menge an Funktionen und Methoden aus der Mathematik und Statistik an.
Für uns ist vor alle das Paket scipy.stats Interessant. Mit ihm können Zufallszahlen aus verschiedensten statistischen Verteilungen generiert werden oder auch statistische Tests durchgeführt werden. Hier finden Sie einen Überblick über alle Methoden des Pakets.
Im folgenden Beispiel wird ein Zweistichproben-t-Test an zwei numerischen Listen durchgeführt.
# import the package stats from the library scipy from scipy import stats # create two numerical arrays x = [12, 10, 11, 13, 14, 10, 13, 13, 22] y = [1, 4, 2, 3, 5, 2, 1, 0, 0, 1, 2] # perform a two sample t-test, to test if the samples have different means stats.</description>
    </item>
    
    <item>
      <title>scitkit-learn</title>
      <link>https://bonartm.github.io/data-librarian/organisation/packages/scikitlearn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/packages/scikitlearn/</guid>
      <description>scikit-learn ist eine umfangreiche Bibliothek für maschinelles Lernen in Python. Es bietet eine Vielzahl an verschiedenen Algorithmen, mit denen zum Beispiel Vorhersagen oder Bilderkennung durchgeführt werden können.
  Faces recognition example using eigenfaces and SVMshttps://scikit-learn.org/stable/auto_examples/applications/plot_face_recognition.html#sphx-glr-auto-examples-applications-plot-face-recognition-py
  # import the packages import numpy as np from sklearn.linear_model import LinearRegression # create some dummy dependent and independent variable X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]]) y = - 1 * X[:,0] + 2 * X[:,1] # estimate a linear regression and print out the coefficients reg = LinearRegression().</description>
    </item>
    
  </channel>
</rss>