<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Modul 3 on data librarian - modul 3 - daten analysieren und verstehen</title>
    <link>https://bonartm.github.io/data-librarian/</link>
    <description>Recent content in Modul 3 on data librarian - modul 3 - daten analysieren und verstehen</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>de-DE</language>
    
	<atom:link href="https://bonartm.github.io/data-librarian/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>numpy</title>
      <link>https://bonartm.github.io/data-librarian/organisation/packages/numpy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/packages/numpy/</guid>
      <description>numpy bietet den array als zentrale Datenstruktur. Mit ihm lassen sich numerische Daten effizient im Arbeitsspeicher (RAM) erstellen, ein- und auslesen, bearbeiten und aggregieren.
Numpy bietet neben dem array viele Funktionen an, mit denen sich effizient Berechnungen auf diesen durchführen lassen können. Außerdem wird die klassische Matrizenrechnung unterstützt.
# import the library and give it a shorter name &#39;np&#39; import numpy as np # create 100 randomly distributed numbers X = np.</description>
    </item>
    
    <item>
      <title>Kurseinheiten</title>
      <link>https://bonartm.github.io/data-librarian/organisation/kurseinheiten/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/kurseinheiten/</guid>
      <description>Wir haben das Modul in wöchentliche Einheiten, die jeweils ein Gebiet aufgreifen und vertiefen, unterteilt. Sie können sich die Zeit für die Bearbeitung der Einheiten selber aufteilen, sollten aber jede Einheit am Ende der jeweiligen Woche abgeschlossen haben. Am Ende einer Woche wird die nächste Einheit auf dieser Webeite freigeschaltet.
Jede Einheit umfasst ein kleines praktisches Projekt, welches Sie in Form eines Jupyter Notebooks bearbeiten und aufbereiten. Ihr Notebook können Sie einreichen, um Feedback von den Kursleitern zu erhalten.</description>
    </item>
    
    <item>
      <title>Termine</title>
      <link>https://bonartm.github.io/data-librarian/organisation/termine/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/termine/</guid>
      <description>Hier finden Sie einen Überblick über die einzelnen Moduleinheiten. Die Tabelle können Sie sich auch als .pdf anzeigen lassen und ausdrucken:
  Überblick Modul 3   überblick_modul3.pdf  (25 ko)       Datum Titel Ziele     21.01 – 26.01 Vorbereitung Installieren Sie die benötigte Software Laden Sie die Kursmaterialien und Datensätze herunter Stellen Sie sicher, dass Python Notebooks lokal ausgeführt werden können   27.</description>
    </item>
    
    <item>
      <title>Conda und Anaconda</title>
      <link>https://bonartm.github.io/data-librarian/organisation/anaconda/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/anaconda/</guid>
      <description>Conda ist eine freie und offene Softwarepaketverwaltung für Python. Neben der Möglichkeit, Pakete (packages, libraries) für Python aus dem Internet zu installieren, können mit conda virtuelle Umgebungen (environments) angelegt werden. Diese Umgebungen beinhalten nur die Pakete und Python Versionen, die für ein spezifisches Projekt gebraucht werden. Umgebungen können mit anderen Personen geteilt werden, sodass sichergestellt ist, dass alle Programmierer mit den gleichen Paketen und Versionen arbeiten, auch wenn sie unterschiedliche Systeme (Windows, Linux, MacOS) verwenden.</description>
    </item>
    
    <item>
      <title>Jupyter Notebooks</title>
      <link>https://bonartm.github.io/data-librarian/organisation/notebooks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/notebooks/</guid>
      <description>Die Projekt-Aufgaben und Code-Beispiele in diesem Modul werden über Jupyter Notebooks erstellt und verteilt.
Jupyter Notebooks bieten eine browserbasierte graphische Schnittstelle zur Python Programmierumgebung. Deswegen können Notebooks auf jedem System gestartet werden, man benötigt dazu nur einen Web-Browser und eine lokale installierte Version von Python.
Darüber hinaus bieten Notebooks die Möglichkeit Text, Visualisierungen und Code in einer integrierten Datei zu erstellen. Somit können einfach statistische Reports und Analysen erstellt werden. Die Replizierbarkeit der Ergebnisse ist auch gewährleistet, da jede Person, die Programmierschritte im Notebook auf ihrem Rechner wiederholen kann.</description>
    </item>
    
    <item>
      <title>San Francisco Library Usage</title>
      <link>https://bonartm.github.io/data-librarian/organisation/materialien/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/materialien/</guid>
      <description>Im ersten Teil des Moduls werden Sie einen offenen Kundendatensatz der Bibliothek in San Francisco analysieren.
 The Integrated Library System (ILS) is composed of bibliographic records including inventoried items, and patron records including circulation data. The data is used in the daily operation of the library, including circulation, online public catalog, cataloging, acquisitions, collection development, processing, and serials control. This dataset represents the usage of inventoried items by patrons &amp;hellip; (Abstract taken from here)</description>
    </item>
    
    <item>
      <title>Recap: Quiz</title>
      <link>https://bonartm.github.io/data-librarian/organisation/quiz/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/quiz/</guid>
      <description>.quiz fieldset { border-color: black; border-width: 10px; margin-bottom: 1em; } .quiz legend { font-size: 105%; font-weight: 600; padding-left: 15px; padding-right: 15px; padding-top: 15px; } .quiz label { display: block; line-height: 1.75em; } .quiz input[type=&#34;radio&#34;] { margin-right: 10px; page-break-after: avoid; page-break-before: avoid; } .quiz input[type=&#34;submit&#34;] { background: black; color: white; display: block; font-size: 120%; font-weight: 600; height: 2.5em; margin-top: 2em; text-transform: uppercase; width: 100%; } .quiz table { color: white; font-weight: bold; margin: 1em auto 2em auto; width: 100%; } .</description>
    </item>
    
    <item>
      <title>Statistik, Data Science und Machine Learning</title>
      <link>https://bonartm.github.io/data-librarian/grundlagen/statistik_ml/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/grundlagen/statistik_ml/</guid>
      <description>Seit einigen Jahren ist der Begriff Data Science sehr populär geworden. Die Nachfrage nach Data Scientists auf dem Arbeitsmarkt ist sehr hoch, Studiengänge werden neu eingerichtet oder umbenannt. Was unterscheidet einen Data Scientist eigentlich von einer Statistikerin?
Machinelles Lernen und insbesondere Themen wie künstliche Intelligenz, Neuronale Netze und Deep Learning sind immer wieder Thema in Zeitungen und Nachrichten. Was bedeuten diese Begriffe und wo ist da der Bezug zur Statistik?</description>
    </item>
    
    <item>
      <title>Der San Francisco Library Usage Dataset</title>
      <link>https://bonartm.github.io/data-librarian/grundlagen/dataset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/grundlagen/dataset/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Grundbegriffe der Statistik</title>
      <link>https://bonartm.github.io/data-librarian/grundlagen/grundbegriffe/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/grundlagen/grundbegriffe/</guid>
      <description>In der Kursumgebung finden Sie das Einführungskapitel des Buchs Statistik: Der Weg zur Datenanalyse hinterlegt.1 Im Text finden Sie Erklärungen und Definition der grundlegenden Begriffe, mit denen Daten charakterisiert werden.
Wenden Sie ihr neu erworbenes Wissen an und diskutieren Sie folgende Fragen konkret für den San Francisco Library Datensatz:
 Wer oder was sind die Merkmalsträger? Wie groß ist die Stichprobengröße des Datensatzes? Wie lässt sich die Grundgesamtheit beschreiben? Handelt es sich um eine Vollerhebung?</description>
    </item>
    
    <item>
      <title>Recap: Lagemaße</title>
      <link>https://bonartm.github.io/data-librarian/deskriptive_statistik/lagema%C3%9Fe/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/deskriptive_statistik/lagema%C3%9Fe/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Streuungsmaße</title>
      <link>https://bonartm.github.io/data-librarian/deskriptive_statistik/streuungsma%C3%9Fe/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/deskriptive_statistik/streuungsma%C3%9Fe/</guid>
      <description>Seit einigen Jahren ist der Begriff Data Science sehr populär geworden. Die Nachfrage nach Data Scientists auf dem Arbeitsmarkt ist sehr hoch, Studiengänge werden neu eingerichtet oder umbenannt. Was unterscheidet einen Data Scientist eigentlich von einer Statistikerin?
Machinelles Lernen und insbesondere Themen wie künstliche Intelligenz, Neuronale Netze und Deep Learning sind immer wieder Thema in Zeitungen und Nachrichten. Was bedeuten diese Begriffe und wo ist da der Bezug zur Statistik?</description>
    </item>
    
    <item>
      <title>Beschreibung von Verteilungen</title>
      <link>https://bonartm.github.io/data-librarian/deskriptive_statistik/dichtefunktion/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/deskriptive_statistik/dichtefunktion/</guid>
      <description>Seit einigen Jahren ist der Begriff Data Science sehr populär geworden. Die Nachfrage nach Data Scientists auf dem Arbeitsmarkt ist sehr hoch, Studiengänge werden neu eingerichtet oder umbenannt. Was unterscheidet einen Data Scientist eigentlich von einer Statistikerin?
Machinelles Lernen und insbesondere Themen wie künstliche Intelligenz, Neuronale Netze und Deep Learning sind immer wieder Thema in Zeitungen und Nachrichten. Was bedeuten diese Begriffe und wo ist da der Bezug zur Statistik?</description>
    </item>
    
    <item>
      <title>Kreuztabellen</title>
      <link>https://bonartm.github.io/data-librarian/deskriptive_statistik/bivariate_verteilungen/kreuztabellen/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/deskriptive_statistik/bivariate_verteilungen/kreuztabellen/</guid>
      <description>Seit einigen Jahren ist der Begriff Data Science sehr populär geworden. Die Nachfrage nach Data Scientists auf dem Arbeitsmarkt ist sehr hoch, Studiengänge werden neu eingerichtet oder umbenannt. Was unterscheidet einen Data Scientist eigentlich von einer Statistikerin?
Machinelles Lernen und insbesondere Themen wie künstliche Intelligenz, Neuronale Netze und Deep Learning sind immer wieder Thema in Zeitungen und Nachrichten. Was bedeuten diese Begriffe und wo ist da der Bezug zur Statistik?</description>
    </item>
    
    <item>
      <title>Korrelation und Kausalität</title>
      <link>https://bonartm.github.io/data-librarian/deskriptive_statistik/bivariate_verteilungen/korrelation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/deskriptive_statistik/bivariate_verteilungen/korrelation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Reflektion: Daten in Ihrem Unternehmen</title>
      <link>https://bonartm.github.io/data-librarian/grundlagen/reflektion/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/grundlagen/reflektion/</guid>
      <description>Schreiben Sie einen kurzen Text über die Verwendung von Daten und quantitativen Methoden auf Ihrer Arbeitstelle. Denken Sie dabei über folgende Fragen nach:
 Welche Daten sind bei Ihnen vorhanden? Mit welchen Daten arbeiten Sie oder würden Sie gerne arbeiten? Werden quantitative Methoden oder Machine Learning bei Ihnen eingesetzt? Welche Fragen oder Phänomene würden Sie gerne mit untersuchen? Was fänden Sie spannend herauszufinden?  ** Teilen Sie ihren Text auf der Kursplatform.</description>
    </item>
    
    <item>
      <title>Beispiele</title>
      <link>https://bonartm.github.io/data-librarian/deskriptive_statistik/visualisierungen/beispiele/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/deskriptive_statistik/visualisierungen/beispiele/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Übung: Filtern von Spalten und Zeilen</title>
      <link>https://bonartm.github.io/data-librarian/grundlagen/pandas/pandas_introduction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/grundlagen/pandas/pandas_introduction/</guid>
      <description> Übung 2: Einführung in Pandas  Laden Sie [dieses Jupyter Notebook]() in Ihren Projektordner. In dem Ordner sollte sich auch der Kunden-Datensatz mit dem Namen Library_Usage.csv befinden. Öffnen und bearbeiten Sie das Notebook mit Jupyter.  </description>
    </item>
    
    <item>
      <title>Überblick</title>
      <link>https://bonartm.github.io/data-librarian/deskriptive_statistik/visualisierungen/%C3%BCberblick/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/deskriptive_statistik/visualisierungen/%C3%BCberblick/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Übung: Berechnung von deskriptive Statistiken</title>
      <link>https://bonartm.github.io/data-librarian/grundlagen/pandas/pandas_%C3%BCbungen/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/grundlagen/pandas/pandas_%C3%BCbungen/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Übung: Visualisierungen</title>
      <link>https://bonartm.github.io/data-librarian/deskriptive_statistik/visualisierungen/%C3%BCbung-visualisierungen/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/deskriptive_statistik/visualisierungen/%C3%BCbung-visualisierungen/</guid>
      <description></description>
    </item>
    
    <item>
      <title>pandas</title>
      <link>https://bonartm.github.io/data-librarian/organisation/packages/pandas/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/packages/pandas/</guid>
      <description>pandas baut auf numpy auf und vereinfacht stark die Bearbeitung, Transformation, Aggregation und Zusammenfassung von zweidimensionalen Datensätzen sowie deren Import und Export in Python. Die zentralen Datenstrukturen in pandas sind Series und DataFrame.
Series sind eindimensionale Listen eines Datentypes, ähnlich wie arrays in numpy. Datentypen können ganzzahlige Zahlen (int), binäre Werte vom Typ true oder false (bool), Strings (str) oder reale Zahlen (float) sein.
In einem DataFrame werden mehrere Series gleicher Länge spaltenweise zu einer zweidimensionalen Tabelle (wie einer Excel Tabelle) zusammengefasst.</description>
    </item>
    
    <item>
      <title>Überblick</title>
      <link>https://bonartm.github.io/data-librarian/inferenzstatistik/%C3%BCberblick/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/inferenzstatistik/%C3%BCberblick/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Konfidenzintervalle</title>
      <link>https://bonartm.github.io/data-librarian/inferenzstatistik/konfidenzintervalle/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/inferenzstatistik/konfidenzintervalle/</guid>
      <description></description>
    </item>
    
    <item>
      <title>matplotlib</title>
      <link>https://bonartm.github.io/data-librarian/organisation/packages/matplotlib/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/packages/matplotlib/</guid>
      <description>matplotlib ist das Standard-Paket zum Erstellen von wissenschaftlichen 2-dimensionalen statischen Graphiken. Die grundlegende Struktur in matplotlib ist figure, eine leere graphische Fläche, die mit Linien, Balken, Punten, Beschriftungen und Axen befüllt werden kann. Der fertige Plot kann dann in diversen Formaten abgespeichert oder auf dem Bildschirm angezeigt werden.
# import the package and give it the shorter name &#39;plt&#39; # matplotlib inline import matplotlib.pyplot as plt # create some dummy data x = range(1, 10) # make a simple scatter plot of the data plt.</description>
    </item>
    
    <item>
      <title>Mittelwertvergleiche</title>
      <link>https://bonartm.github.io/data-librarian/inferenzstatistik/mittelwertvergleich/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/inferenzstatistik/mittelwertvergleich/</guid>
      <description></description>
    </item>
    
    <item>
      <title>seaborn</title>
      <link>https://bonartm.github.io/data-librarian/organisation/packages/seaborn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/packages/seaborn/</guid>
      <description>seaborn baut auf matplotlib auf und bietet eine Vielzahl von Funktionen, die es erlauben schnell und einfach schöne statistische Visualisierungen zu erstellen. Seaborn ist also keine komplett eigenenständige Graphik-Bibliothek, sondern nutzt intern die Funktionalitäten und Datenstrukturen von matplotlib.
Eine wichtige Funktion ist die sns.set() Methode. Wenn sie am Anfang eines Python-Scripts ausgeführt wird, wird intern das Design der Plots erheblich verbessert. Alle plots, die nach dem Aufruf der Funktion erstellt werden, sehen viel besser aus.</description>
    </item>
    
    <item>
      <title>scipy</title>
      <link>https://bonartm.github.io/data-librarian/organisation/packages/scipy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/packages/scipy/</guid>
      <description>scipy ist fest mit numpy und pandas verbunden und bietet eine Menge an Funktionen und Methoden aus der Mathematik und Statistik an.
Für uns ist vor alle das Paket scipy.stats Interessant. Mit ihm können Zufallszahlen aus verschiedensten statistischen Verteilungen generiert werden oder auch statistische Tests durchgeführt werden. Hier finden Sie einen Überblick über alle Methoden des Pakets.
Im folgenden Beispiel wird ein Zweistichproben-t-Test an zwei numerischen Listen durchgeführt.
# import the package stats from the library scipy from scipy import stats # create two numerical arrays x = [12, 10, 11, 13, 14, 10, 13, 13, 22] y = [1, 4, 2, 3, 5, 2, 1, 0, 0, 1, 2] # perform a two sample t-test, to test if the samples have different means stats.</description>
    </item>
    
    <item>
      <title>scitkit-learn</title>
      <link>https://bonartm.github.io/data-librarian/organisation/packages/scikitlearn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/packages/scikitlearn/</guid>
      <description>scikit-learn ist eine umfangreiche Bibliothek für maschinelles Lernen in Python. Es bietet eine Vielzahl an verschiedenen Algorithmen, mit denen zum Beispiel Vorhersagen oder Bilderkennung durchgeführt werden können.
  Faces recognition example using eigenfaces and SVMshttps://scikit-learn.org/stable/auto_examples/applications/plot_face_recognition.html#sphx-glr-auto-examples-applications-plot-face-recognition-py
  # import the packages import numpy as np from sklearn.linear_model import LinearRegression # create some dummy dependent and independent variable X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]]) y = - 1 * X[:,0] + 2 * X[:,1] # estimate a linear regression and print out the coefficients reg = LinearRegression().</description>
    </item>
    
  </channel>
</rss>