<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Modul 3 on data librarian - modul 3 - daten analysieren und verstehen</title>
    <link>https://bonartm.github.io/data-librarian/</link>
    <description>Recent content in Modul 3 on data librarian - modul 3 - daten analysieren und verstehen</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>de-DE</language>
    
	<atom:link href="https://bonartm.github.io/data-librarian/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Häufigkeiten</title>
      <link>https://bonartm.github.io/data-librarian/descriptive_statistics/univariate/frequency/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/descriptive_statistics/univariate/frequency/</guid>
      <description>Kategoriale (nominale und ordinale) Variablen werden in Häufigkeitstabellen zusammengefasst. Dabei wird für jede Ausprägung die Anzahl der Beobachtungen gezählt:
import pandas as pd df = pd.read_csv(&amp;#34;../data/Library_Usage.csv&amp;#34;) df[&amp;#39;Age Range&amp;#39;].value_counts()    Mit der Funktion value_counts() können Sie sich absolute Häufigkeitstabellen ausgeben lassen. Mit dem zusätzlichen Argumentaufruf normalize=True werden relative Häufigkeiten berechnet:
df[&amp;#39;Age Range&amp;#39;].value_counts(normalize=True)    Der Modus ist dabei die Merkmalsausprägung, die die meisten Beobachtungen besitzen: age_mode = df[&amp;#39;Age Range&amp;#39;].</description>
    </item>
    
    <item>
      <title>Lösungen zu den Kursaufgaben</title>
      <link>https://bonartm.github.io/data-librarian/solutions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/solutions/</guid>
      <description>Im Laufe des Kurses werden hier die Lösungen zu den einzelnen Aufgaben hochgeladen. Die Projektaufgaben werden am Präsenztag gesammelt besprochen.
Kursorganisation und Vorbereitung Quiz  Strg+Enter siehe hier: https://docs.anaconda.com/anaconda/packages/pkg-docs/ 423448, len(df) siehe (unter sns.set()): https://seaborn.pydata.org/introduction.html  Jan gilt.), diskret, `object` - `temp`: metrisch, stetig, `int` - `below_zero`: nominal, diskret, `boolean` #### Datenrundreise   Lösungen   solutions_datenrundreise.ipynb  (35 ko)    #### Exkurs: Einlesen von Daten - In Linux kann z.</description>
    </item>
    
    <item>
      <title>numpy</title>
      <link>https://bonartm.github.io/data-librarian/organisation/packages/numpy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/packages/numpy/</guid>
      <description>numpy bietet den array als zentrale Datenstruktur. Mit ihm lassen sich numerische Daten effizient im Arbeitsspeicher (RAM) erstellen, ein- und auslesen, bearbeiten und aggregieren.
Numpy bietet neben dem array viele Funktionen an, mit denen sich effizient Berechnungen auf diesen durchführen lassen können. Außerdem wird die klassische Matrizenrechnung unterstützt.
# import the library and give it a shorter name &amp;#39;np&amp;#39; import numpy as np # create 100 randomly distributed numbers X = np.</description>
    </item>
    
    <item>
      <title>Series und DataFrames</title>
      <link>https://bonartm.github.io/data-librarian/basics/pandas/series/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/basics/pandas/series/</guid>
      <description>Series und DataFrames sind die zentralen Datenstrukturen in Pandas. Series sind wie standardmäßige Listen in Python, mit dem wichtigen Unterschied, dass Series nur Werte eines einzelnen Datentyps enthalten können.
import pandas as pd x = pd.Series([34, 12, 23, 45]) print(x) x.dtype    Ein Datentyp ist die grundlegende Einheit, in der einzelne Werte in einer Programmiersprache vom Computer gespeichert und verarbeitet werden können. Beispiele für Datentypen in pandas sind: float für Gleitkommazahlen, int für Ganzzahlen, bool für binäre True, False Werte oder datetime für Datumswerte.</description>
    </item>
    
    <item>
      <title>Statistik</title>
      <link>https://bonartm.github.io/data-librarian/basics/ml/statistic/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/basics/ml/statistic/</guid>
      <description>Justus Perthes (1838): Rhein, Elbe und Oder   Statistik ist die traditionelle Wissenschaft von der Erhebung und Analyse von Daten. Sie verfügt über eine großes theoretisches und mathematisches Fundament und lässt sich in die Teilgebiete deskriptive (Beschreiben), explorative (Suchen) und schließende (Induktion) Statistik unterteilen.
Lesen Sie mehr über die Grundlagen der Statistik im Kapitel Grundbegriffe der Statistik.</description>
    </item>
    
    <item>
      <title>Statistische Inferenz</title>
      <link>https://bonartm.github.io/data-librarian/inference/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/inference/overview/</guid>
      <description>Bisher haben Sie vorliegende Daten einer Stichprobe mit Visualisierungen und Statistiken beschrieben und zusammengefasst. Von Interesse sind aber in der Regel, die Zusammenhänge und Statistiken in der Gesamtpopulation.
Beispiel Wahlumfrage: Sie ziehen zufällig $n=100$ Personen aus dem Wahlregister und befragen Sie nach ihren Parteipräferenzen. Sie können dann beispielsweise den relativen Anteil der Personen in Ihrer Stichprobe, die eine bestimmte Partei favorisieren, bestimmen. Damit haben Sie einen Schätzwert für den tatsächlichen Wert, wenn Sie alle Personen des Wahlregisters befragt hätten.</description>
    </item>
    
    <item>
      <title>Ein- und Ausgabe</title>
      <link>https://bonartm.github.io/data-librarian/basics/pandas/io/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/basics/pandas/io/</guid>
      <description>Die Funktionen zur Ein- und Ausgabe von Daten in pandas sind umfangreich aber systematisch organisiert. Um beispielsweise eine .csv Datei einzulesen und in einer Variable zu speichern verwenden Sie die Funktion read_csv:
import pandas as pd df = pd.read_csv(&amp;#34;../data/Library_Usage.csv&amp;#34;) df.head()    Um einen eingelesenen Datensatz beispielsweise im .json Textformat zu speichern verwenden Sie die Funktion to_json:
df.to_json(&amp;#34;../data/Library_Usage.json&amp;#34;)     Manche Funktion aus dem pandas Paket sind statische Funktionen: Sie sind an kein konkretes Objekt wie ein DataFrame gebunden, sondern werden über den Bibliotheksnamen pd aufgerufen.</description>
    </item>
    
    <item>
      <title>Machine Learning</title>
      <link>https://bonartm.github.io/data-librarian/basics/ml/ml/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/basics/ml/ml/</guid>
      <description>Seit der Erfindung des Personal Computers und des Internets werden statistische Probleme immer komplexer und größer. Die Datenmengen erfordern neue effiziente Strukturen zum Speichern und Auffinden der Informationen.
Maschinelles Lernen (Machine Learning oder Statistical Learning) bedeutet in diesem Kontext relevante und signifikante Muster und Trends aus den Daten zu extrahieren um die Daten &amp;ldquo;zu verstehen&amp;rdquo;. Dabei spielen Computer und deren wachsende Rechenpower eine immer größere Rolle. Sie haben die klassische angewandte Statistik revolutioniert und es sind vor allem Ingenieure und Informatiker, die die Weiterentwicklung der Disziplin heutzutage vorantreiben.</description>
    </item>
    
    <item>
      <title>Auswahl und Erstellung von Spalten</title>
      <link>https://bonartm.github.io/data-librarian/basics/pandas/columns/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/basics/pandas/columns/</guid>
      <description>Die Spalten eines DataFrames werden über einen Spaltenindex referenziert. Üblicherweise besteht der Spaltenindex aus Spaltennamen in Textform:
import pandas as pd df = pd.read_csv(&amp;#34;../data/Library_Usage.csv&amp;#34;) df.columns    Einzelne Spalten können wie bei einem Python Dictionary mit df[&amp;lt;name&amp;gt;] ausgewählt werden. Mehre Spalten mit df[[&amp;lt;name1&amp;gt;, &amp;lt;name2]]. Wenn Sie mehrere Spalten auswählen erhalten Sie einen DataFrame zurück. Bei einer Spalte, eine Series. Das Ergebnis der Auswahl können Sie bei Bedarf wieder in einer Variablen abspeichern:</description>
    </item>
    
    <item>
      <title>Data Science</title>
      <link>https://bonartm.github.io/data-librarian/basics/ml/data-science/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/basics/ml/data-science/</guid>
      <description>Ein Data Scientist ist eine Person, die oder der Wissen und Erkenntnisse aus strukturierten und unstrukturierten Daten gewinnt. Data Science ist eine interdisziplinäre Disziplin und liegt irgendwo in der Schnittmenge von angewandter Statistik, angewandter Informatik (Hacking skills) und spezielles Fachwissen (domain knowledge/ substantive expertise).
Aufgrund der stark angewachsenen Mengen an unstrukturierten Daten aus heterogenen Datenquellen (Text, Bilder, Sensoren, Netzwerke, Videos, &amp;hellip;) reichen die Methoden und Fertigkeiten, die die Statistik traditionellerweise liefert und vermittelt, nicht mehr aus, um diese Daten effizient zu strukturieren, aggregieren, kombinieren, analysieren und visualisieren zu können:</description>
    </item>
    
    <item>
      <title>Auswahl von Zeilen</title>
      <link>https://bonartm.github.io/data-librarian/basics/pandas/rows/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/basics/pandas/rows/</guid>
      <description>Die Zeilen eines DataFrames werden über einen Zeilenindex (loc[]), über die aufsteigenden Zeilennummern (iloc[]) oder über logische Ausdrücke ([] oder loc[]) referenziert.
Hier wird nur der wichtigste letzte Fall näher betrachtet:
import pandas as pd df = pd.read_csv(&amp;#34;../data/Library_Usage.csv&amp;#34;) df[df[&amp;#39;Total Checkouts&amp;#39;] &amp;gt; 10000]    Der Ausdruck df[&#39;Total Checkouts&#39;] &amp;gt; 10000 wird zuerst ausgewertet und ergibt eine boolesche Series mit Einträgen True wenn die Beobachtung mehr als 1000 Ausleihen getätigt hat und False sonst.</description>
    </item>
    
    <item>
      <title>Exkurs: Fehlende Werte</title>
      <link>https://bonartm.github.io/data-librarian/basics/pandas/na/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/basics/pandas/na/</guid>
      <description>Real erhobene Daten sind meistens unsauber und fehlerhaft. Ein häufiges Problem dabei sind fehlende Werte, also Beobachtungen für die manche Merkmale nicht erhoben wurden. In jedem Datensatz werden fehlende Werte anders gekennzeichnet, aber man findet oft diese Kodierungen wieder: &amp;quot;-999&amp;quot;, &amp;quot;NA&amp;quot;, &amp;quot; &amp;quot;, &amp;quot;None&amp;quot;, &amp;quot;NULL&amp;quot;, &amp;quot;#N/A&amp;quot;.
Wenn beispielsweise der Mittelwert einer statistischen Variable berechnet wird, so muss entschieden werden, wie mit fehlenden Werten umgegangen werden soll: Sollen die Werte entfernt werden?</description>
    </item>
    
    <item>
      <title>Überblick: Funktionen in Pandas</title>
      <link>https://bonartm.github.io/data-librarian/basics/pandas/functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/basics/pandas/functions/</guid>
      <description>Mit df.head() können Sie sich die ersten $n$ Zeilen eines DataFrames anzeigen lassen:
import pandas as pd df = pd.read_csv(&amp;#34;../data/Library_Usage.csv&amp;#34;) df.head()    Analog dazu funktioniert die Funktion df.tail().
Pandas Funktionen (5 Min)
Schauen Sie sich die Dokumentation für die Funktion head() hier an. Wie können Sie sich die ersten $100$ Zeilen anzeigen lassen?
  Mit df.info() erhalten Sie speicherbezogene Informationen über das Objekt. Mit df.describe() werden nützliche deskriptive Statistiken für alle numerischen Spalten eines Datensatzes ausgegeben.</description>
    </item>
    
    <item>
      <title>Kurseinheiten</title>
      <link>https://bonartm.github.io/data-librarian/organisation/modules/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/modules/</guid>
      <description>Wir haben das Modul in wöchentliche Einheiten, die jeweils ein Gebiet aufgreifen und vertiefen, unterteilt. Sie können sich die Zeit für die Bearbeitung der Einheiten selber aufteilen, sollten aber jede Einheit am Ende der jeweiligen Woche abgeschlossen haben. Am Ende einer Woche wird die nächste Einheit auf dieser Webeite freigeschaltet.
Jede Einheit umfasst kleine praktische Projektaufgaben, welche Sie in Form eines Jupyter Notebooks bearbeiten und aufbereiten. Zu jeder Einheit werden viele verschiedene Aufgaben mit unterschiedlichem Schwierigkeitsgrad angeboten.</description>
    </item>
    
    <item>
      <title>Termine</title>
      <link>https://bonartm.github.io/data-librarian/organisation/schedule/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/schedule/</guid>
      <description>Hier finden Sie einen Überblick über die einzelnen Moduleinheiten.
   Datum Titel Ziele     21.01 – 26.01 Vorbereitung Installieren Sie die benötigte Software Laden Sie die Kursmaterialien und Datensätze herunter Stellen Sie sicher, dass Python Notebooks lokal ausgeführt werden können   27.01 – 02.02 Grundlagen Beschreiben Sie Datensätze mit dem statistischen Grundvokabular Lesen Sie Datensätze als DataFrames in Python ein Filtern Sie DataFrames nach Spalten oder Zeilen Erstellen Sie neue Variablen   03.</description>
    </item>
    
    <item>
      <title>Conda und Anaconda</title>
      <link>https://bonartm.github.io/data-librarian/organisation/anaconda/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/anaconda/</guid>
      <description>Conda ist eine freie und offene Softwarepaketverwaltung für Python. Neben der Möglichkeit, Pakete (packages, libraries) für Python aus dem Internet zu installieren, können mit conda virtuelle Umgebungen (environments) angelegt werden. Diese Umgebungen beinhalten nur die Pakete und Python Versionen, die für ein spezifisches Projekt gebraucht werden. Umgebungen können mit anderen Personen geteilt werden, sodass sichergestellt ist, dass alle Programmierer mit den gleichen Paketen und Versionen arbeiten, auch wenn sie unterschiedliche Systeme (Windows, Linux, MacOS) verwenden.</description>
    </item>
    
    <item>
      <title>Jupyter Notebooks</title>
      <link>https://bonartm.github.io/data-librarian/organisation/notebooks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/notebooks/</guid>
      <description>Die Projekt-Aufgaben und Code-Beispiele in diesem Modul werden über Jupyter Notebooks erstellt und verteilt.
Jupyter Notebooks bieten eine browserbasierte graphische Schnittstelle zur Python Programmierumgebung. Deswegen können Notebooks auf jedem System gestartet werden, man benötigt dazu nur einen Web-Browser und eine lokale installierte Version von Python.
Darüber hinaus bieten Notebooks die Möglichkeit Text, Visualisierungen und Code in einer integrierten Datei zu erstellen. Somit können einfach statistische Reports und Analysen erstellt werden. Die Replizierbarkeit der Ergebnisse ist auch gewährleistet, da jede Person, die Programmierschritte im Notebook auf dem eignen Rechner wiederholen kann.</description>
    </item>
    
    <item>
      <title>San Francisco Library Usage</title>
      <link>https://bonartm.github.io/data-librarian/organisation/dataset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/dataset/</guid>
      <description>Im ersten Teil des Moduls werden Sie einen offenen Kundendatensatz der Bibliothek in San Francisco analysieren.
 The Integrated Library System (ILS) is composed of bibliographic records including inventoried items, and patron records including circulation data. The data is used in the daily operation of the library, including circulation, online public catalog, cataloging, acquisitions, collection development, processing, and serials control. This dataset represents the usage of inventoried items by patrons &amp;hellip; (Abstract taken from here)</description>
    </item>
    
    <item>
      <title>Recap: Quiz</title>
      <link>https://bonartm.github.io/data-librarian/organisation/quiz_intro/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/quiz_intro/</guid>
      <description>.quiz fieldset { border-color: black; border-width: 10px; margin-bottom: 1em; } .quiz legend { font-size: 105%; font-weight: 600; padding-left: 15px; padding-right: 15px; padding-top: 15px; } .quiz label { display: block; line-height: 1.75em; } .quiz input[type=&#34;radio&#34;] { margin-right: 10px; page-break-after: avoid; page-break-before: avoid; } .quiz input[type=&#34;submit&#34;] { background: black; color: white; display: block; font-size: 120%; font-weight: 600; height: 2.5em; margin-top: 2em; text-transform: uppercase; width: 100%; } .quiz table { color: white; font-weight: bold; margin: 1em auto 2em auto; width: 100%; } .</description>
    </item>
    
    <item>
      <title>Grundbegriffe der Statistik</title>
      <link>https://bonartm.github.io/data-librarian/basics/basic_terms/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/basics/basic_terms/</guid>
      <description>In der Kursumgebung finden Sie das Einführungskapitel des Buchs Statistik: Der Weg zur Datenanalyse zum alleinigen persönlichen Gebrauch hier im Kurs hinterlegt.1
 Eine weitere sehr gute und modernere Einstiegsliteratur sind die englischen Lehrbücher von OpenIntro. Sie können kostenlos auf der Webseite heruntergeladen werden. Für diesen Kurs sind insbesondere die ersten zwei Kapitel des Buchs Introductory Statistics with Randomization and Simulation zu empfehlen. 2
 Der Text gibt einen Einstieg in die Aufgaben und Anwendungsbereiche der Statistik und erklärt die grundlegenden Begriffe, mit denen Daten und Datensätze charakterisiert werden können.</description>
    </item>
    
    <item>
      <title>Lagemaße</title>
      <link>https://bonartm.github.io/data-librarian/descriptive_statistics/univariate/mean/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/descriptive_statistics/univariate/mean/</guid>
      <description>Für metrische Variablen beschreiben Lagemaße die Zentralität einer Verteilung. Das bekannteste Lagemaß ist der empirische Mittelwert:
$$ \bar{x} = \frac{1}{n}\sum_{i=1}^{n}x_i = \frac{x_1 + x_2 + \dots + x_n}{n} $$
import pandas as pd df = pd.read_csv(&amp;#34;../data/Library_Usage.csv&amp;#34;) df[&amp;#39;Total Checkouts&amp;#39;].mean()    Eine zweite wichtige Statistik ist der Median. Er ergibt sich aus dem Wert der Beobachtung, die die nach der Größe geordnete Messreihe in genau zwei gleich große Teile teilt. Für eine gerade Anzahl an Beobachtung wird der Mittelwert der Beobachtung an der Stelle $n/2$ und $n/2+1$ genommen:</description>
    </item>
    
    <item>
      <title>Streuungsmaße</title>
      <link>https://bonartm.github.io/data-librarian/descriptive_statistics/univariate/variance/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/descriptive_statistics/univariate/variance/</guid>
      <description>Die Zentralität einer Verteilung ist nur eine wichtige Kennzahl. Streuungsmaße geben zusätzlich an, wie stark die Daten einer Messreihe schwanken. Die Streuung einer Variable ist entscheidend z.B. bei der Beurteilung wie Wahrscheinlich extreme Werte vorkommen können.
Varianz Die Distanz einer Beobachtung vom Mittelwert der zugrundeliegenden Variable wird Abweichung genannt. Der Mittelwert über die quadrierten Abweichungen wird als Varianz definiert:
$$ s^2_x = \frac{1}{n-1}\sum_{i=1}^{n}(x_i-\bar{x})^2 $$
df[&amp;#39;Total Checkouts&amp;#39;].var()    Das Quadrieren der Abweichungen hat zur Folge, dass das Vorzeichen verschwindet und das große Abweichungen mehr Gewicht erhalten.</description>
    </item>
    
    <item>
      <title>Symmetrie und Schiefe</title>
      <link>https://bonartm.github.io/data-librarian/descriptive_statistics/univariate/symmetrie/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/descriptive_statistics/univariate/symmetrie/</guid>
      <description>Verschiedene univariate Verteilungen     Related files   distributions.ipynb  (74 ko)    Um eine metrische Verteilung charakterisieren zu können, ist neben der zentralen Lage- und Streuung auch deren Symmetrie und Schiefe von Bedeutung. Die Symmetrie sagt etwas über die (Un-)Gleichverteilung einer Variablen aus. Bei stark assymetrischen Variablen (z.B. Haushaltseinkommen in Deutschland) ist das auftreten von kleinen Werten viel wahrscheinlicher, als das auftreten von sehr großen Werten (oder umgekehrt).</description>
    </item>
    
    <item>
      <title>Bivariate Verteilungen</title>
      <link>https://bonartm.github.io/data-librarian/descriptive_statistics/bivariate/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/descriptive_statistics/bivariate/</guid>
      <description>Bisher haben Sie immer nur einzelne Variable betrachtet, zusammengefasst oder visualisiert. In vielen Fällen ist jedoch der Zusammenhang zwischen zwei Variablen von Interesse. Nach dieser Einheit sollten Sie die folgenden Fragen beantworten können:
 Leihen ältere Bibliothekskunden im Schnitt mehr Bücher aus als jüngere? Führen Kunden, die häufiger Ausleihen tätigen, im Schnitt auch häufiger Verlängerungen durch? Nimmt die Anzahl der Ausleihen mit zunehmender Dauer der Mitgliedschaft ab?  Zwei Variablen, die keinen Zusammenhang aufweisen, nennt man statistisch unabhängige Variablen.</description>
    </item>
    
    <item>
      <title>Reflexion: Daten an Ihrem Arbeitsplatz</title>
      <link>https://bonartm.github.io/data-librarian/basics/reflection/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/basics/reflection/</guid>
      <description>Reflektion (15 Min) Schreiben Sie einen kurzen Text über die Verwendung von Daten und quantitativen Methoden an Ihrem Arbeitsplatz. Denken Sie dabei über folgende Fragen nach:
 Welche Daten sind bei Ihnen vorhanden? Mit welchen Daten arbeiten Sie oder würden Sie gerne arbeiten? Werden statistische Verfahren oder Maschinelles Lernen schon bei Ihnen eingesetzt? Welche Fragen oder Phänomene würden Sie gerne untersuchen? Was fänden Sie spannend herauszufinden?  Teilen Sie Ihren Text mit den anderen KursteilnehmerInnen im Forum zu Modul 3 auf der Kursplattform.</description>
    </item>
    
    <item>
      <title>Tutorial</title>
      <link>https://bonartm.github.io/data-librarian/descriptive_statistics/visualizations/tutorial/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/descriptive_statistics/visualizations/tutorial/</guid>
      <description>Statistical analysis is a process of understanding how variables in a dataset relate to each other and how those relationships depend on other variables. Visualization can be a core component of this process because, when data are visualized properly, the human visual system can see trends and patterns that indicate a relationship. (https://seaborn.pydata.org/tutorial/relational.html)
 Die zahlreichen Funktionen, die seaborn bietet basieren immer auf dem gleichen Prinzip: Visualisiert werden (nominale, ordinale, metrische) Variablen eines Datensatzes, die in Form eines DataFrames vorliegt.</description>
    </item>
    
    <item>
      <title>Weitere Beispiele</title>
      <link>https://bonartm.github.io/data-librarian/descriptive_statistics/visualizations/examples/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/descriptive_statistics/visualizations/examples/</guid>
      <description>Im Tutorial haben Sie gesehen, wie Sie ein Streudiagramm erstellen können. Hier werden exemplarisch weitere Möglichkeiten gezeigt, die Daten des Datensatzes zu visualisieren. Die wichtigste Funktion ist hierbei sns.catplot().
import pandas as pd import seaborn as sns import matplotlib.pyplot as plt import numpy as np # matplotlib inline sns.set() df = pd.read_csv(&amp;#34;../data/Library_Usage.csv&amp;#34;) Nominale und ordinale Variablen Univariate Häufigkeits- und Bivariate Kreuztatabellen können mit Balkendiagrammen visualisiert werden:
sns.catplot(y=&amp;#39;Year Patron Registered&amp;#39;, data=df, kind=&amp;#39;count&amp;#39;, color=&amp;#34;steelblue&amp;#34;) sns.</description>
    </item>
    
    <item>
      <title>Recap: Quiz</title>
      <link>https://bonartm.github.io/data-librarian/basics/quiz_pandas/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/basics/quiz_pandas/</guid>
      <description>.quiz fieldset { border-color: black; border-width: 10px; margin-bottom: 1em; } .quiz legend { font-size: 105%; font-weight: 600; padding-left: 15px; padding-right: 15px; padding-top: 15px; } .quiz label { display: block; line-height: 1.75em; } .quiz input[type=&#34;radio&#34;] { margin-right: 10px; page-break-after: avoid; page-break-before: avoid; } .quiz input[type=&#34;submit&#34;] { background: black; color: white; display: block; font-size: 120%; font-weight: 600; height: 2.5em; margin-top: 2em; text-transform: uppercase; width: 100%; } .quiz table { color: white; font-weight: bold; margin: 1em auto 2em auto; width: 100%; } .</description>
    </item>
    
    <item>
      <title>Recap: Quiz</title>
      <link>https://bonartm.github.io/data-librarian/descriptive_statistics/quiz_statistics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/descriptive_statistics/quiz_statistics/</guid>
      <description>.quiz fieldset { border-color: black; border-width: 10px; margin-bottom: 1em; } .quiz legend { font-size: 105%; font-weight: 600; padding-left: 15px; padding-right: 15px; padding-top: 15px; } .quiz label { display: block; line-height: 1.75em; } .quiz input[type=&#34;radio&#34;] { margin-right: 10px; page-break-after: avoid; page-break-before: avoid; } .quiz input[type=&#34;submit&#34;] { background: black; color: white; display: block; font-size: 120%; font-weight: 600; height: 2.5em; margin-top: 2em; text-transform: uppercase; width: 100%; } .quiz table { color: white; font-weight: bold; margin: 1em auto 2em auto; width: 100%; } .</description>
    </item>
    
    <item>
      <title>Das Bootstrapping Verfahren</title>
      <link>https://bonartm.github.io/data-librarian/inference/bootstrap/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/inference/bootstrap/</guid>
      <description>Das Ziel der Inferenzstatistik ist es, aus einer einzelnen Stichprobe $x_1, \dots, x_n$ die Stichproben-Verteilung eines Schätzers, wie dem Mittelwert $\bar{x}$ oder dem Median $x_{0.5}$, herzuleiten. Wenn die Stichproben-Verteilung eines Schätzers vorliegt kann damit der Wert des tatsächlichen unbekannten Populationsparameters eingegrenzt werden.
Für viele Schätzer kann deren Stichproben-Verteilug theoretisch hergeleitet werden. Neben der theoretischen Herangehensweise, gibt es auch eine intuitive empirische Methode, das Bootstrapping-Verfahren. Es basiert auf der Simulation von vielen Stichproben.</description>
    </item>
    
    <item>
      <title>pandas</title>
      <link>https://bonartm.github.io/data-librarian/organisation/packages/pandas/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/packages/pandas/</guid>
      <description>pandas baut auf numpy auf und vereinfacht stark die Bearbeitung, Transformation, Aggregation und Zusammenfassung von zweidimensionalen Datensätzen sowie deren Import und Export in Python. Die zentralen Datenstrukturen in pandas sind Series und DataFrame.
Series sind eindimensionale Listen eines Datentypes, ähnlich wie arrays in numpy. Datentypen können ganzzahlige Zahlen (int), binäre Werte vom Typ true oder false (bool), Strings (str) oder reale Zahlen (float) sein.
In einem DataFrame werden mehrere Series gleicher Länge spaltenweise zu einer zweidimensionalen Tabelle (wie einer Excel Tabelle) zusammengefasst.</description>
    </item>
    
    <item>
      <title>matplotlib</title>
      <link>https://bonartm.github.io/data-librarian/organisation/packages/matplotlib/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/packages/matplotlib/</guid>
      <description>matplotlib ist das Standard-Paket zum Erstellen von wissenschaftlichen 2-dimensionalen statischen Graphiken. Die grundlegende Struktur in matplotlib ist figure, eine leere graphische Fläche, die mit Linien, Balken, Punten, Beschriftungen und Axen befüllt werden kann. Der fertige Plot kann dann in diversen Formaten abgespeichert oder auf dem Bildschirm angezeigt werden.
# import the package and give it the shorter name &amp;#39;plt&amp;#39; # matplotlib inline import matplotlib.pyplot as plt # create some dummy data x = range(1, 10) # make a simple scatter plot of the data plt.</description>
    </item>
    
    <item>
      <title>Konfidenzintervalle und Signifikanz</title>
      <link>https://bonartm.github.io/data-librarian/inference/significance/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/inference/significance/</guid>
      <description>Im vorherigen Beispiel haben Sie mit Hilfe des Bootstrapping-Verfahrens die Stichprobenverteilung geschätzt. Wenn die Stichprobenverteilung bekannt ist, können damit Aussagen über den tatsächlichen Parameter in der Population (im Bild mit $\mu$ bezeichnet) getroffen werden.
Eine häufig angewandte Methode sind Konfidenzintervalle (KI). Sie geben einen Bereich aus der Stichprobenverteilung des Schätzwertes an, der den wahren Wert in der Population mit hoher Wahrscheinlichkeit überdeckt. Die Wahrscheinlichkeit wird mit $1-\alpha$ angegeben. Der Wert $\alpha$ wird Signifikanzniveau gennannt und vor der Bestimmung des Intervalls festgelegt.</description>
    </item>
    
    <item>
      <title>seaborn</title>
      <link>https://bonartm.github.io/data-librarian/organisation/packages/seaborn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/packages/seaborn/</guid>
      <description>seaborn baut auf matplotlib auf und bietet eine Vielzahl von Funktionen, die es erlauben schnell und einfach schöne statistische Visualisierungen zu erstellen. Seaborn ist also keine komplett eigenenständige Graphik-Bibliothek, sondern nutzt intern die Funktionalitäten und Datenstrukturen von matplotlib.
Eine wichtige Funktion ist die sns.set() Methode. Wenn sie am Anfang eines Python-Scripts ausgeführt wird, wird intern das Design der Plots erheblich verbessert. Alle plots, die nach dem Aufruf der Funktion erstellt werden, sehen viel besser aus.</description>
    </item>
    
    <item>
      <title>Mittelwertvergleiche</title>
      <link>https://bonartm.github.io/data-librarian/inference/two-sample-test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/inference/two-sample-test/</guid>
      <description>Ein häufiges Problem bei der statistischen Datenanalyse ist die Frage, ob signifikante Unterschiede in den Mittelwerten zweier Subpopulationen bestehen: Leihen Frauen beispielsweise im Mittel signifikant mehr aus als männliche Bibliothekskunden? Tätigen Kunden im Ruhestand im Mittel weniger Verlängerungen als junge Kunden?
Von einem signifikanten Unterschied spricht man, wenn die Differenz zwischen den Mittelwerten zweier Stichproben so groß ist, dass es sehr Unwahrscheinlich ist, dass dieser Unterschied alleine aufgrund der rein zufälligen Schwankungen durch die Stichprobenziehung enstanden ist.</description>
    </item>
    
    <item>
      <title>scipy</title>
      <link>https://bonartm.github.io/data-librarian/organisation/packages/scipy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/packages/scipy/</guid>
      <description>scipy ist fest mit numpy und pandas verbunden und bietet eine Menge an Funktionen und Methoden aus der Mathematik und Statistik an.
Für uns ist vor alle das Paket scipy.stats Interessant. Mit ihm können Zufallszahlen aus verschiedensten statistischen Verteilungen generiert werden oder auch statistische Tests durchgeführt werden. Hier finden Sie einen Überblick über alle Methoden des Pakets.
Im folgenden Beispiel wird ein Zweistichproben-t-Test an zwei numerischen Listen durchgeführt.
# import the package stats from the library scipy from scipy import stats # create two numerical arrays x = [12, 10, 11, 13, 14, 10, 13, 13, 22] y = [1, 4, 2, 3, 5, 2, 1, 0, 0, 1, 2] # perform a two sample t-test, to test if the samples have different means stats.</description>
    </item>
    
    <item>
      <title>scitkit-learn</title>
      <link>https://bonartm.github.io/data-librarian/organisation/packages/scikitlearn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bonartm.github.io/data-librarian/organisation/packages/scikitlearn/</guid>
      <description>scikit-learn ist eine umfangreiche Bibliothek für maschinelles Lernen in Python. Es bietet eine Vielzahl an verschiedenen Algorithmen, mit denen zum Beispiel Vorhersagen oder Bilderkennung durchgeführt werden können.
  Faces recognition example using eigenfaces and SVMshttps://scikit-learn.org/stable/auto_examples/applications/plot_face_recognition.html#sphx-glr-auto-examples-applications-plot-face-recognition-py
  # import the packages import numpy as np from sklearn.linear_model import LinearRegression # create some dummy dependent and independent variable X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]]) y = - 1 * X[:,0] + 2 * X[:,1] # estimate a linear regression and print out the coefficients reg = LinearRegression().</description>
    </item>
    
  </channel>
</rss>